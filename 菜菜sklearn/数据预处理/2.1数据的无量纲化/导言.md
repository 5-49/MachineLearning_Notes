数据挖掘的五大步骤：

1. 获取数据
2. 数据预处理：纠正/删除损坏不准确或者不适用于模型的数据
3. 特征工程：将原始数据转换成更能代表预测模型的潜在问题的特征的过程，常用降维算法
4. 建模：测试模型并预测出结果
5. 上线：验证模型效果


sklearn的模块基本上包括了预处理需要的

- preprocessing：数据预处理
- impute：填补缺失值
- feature_selection：特征值选择的各种方法的实践
- decomposition：降维算法
  
除了决策树和随机森林之外（这两个可以把所有类型的数据都处理的很好），其他所有的模型需要的数据都要无量纲化
线性的无量纲化：中心化处理（减去应该固定值，将所有数据平移），缩放处理（除以一个固定值或取对数，将数据固定在某个范围内）

数据的无量纲化，有归一化和标准化。一般来说采用标准化，由于归一化对于异常值过于敏感。 